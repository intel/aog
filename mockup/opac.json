{
  "version": "v0.1",
  "service_providers": {
    "remote_ollama_chat": {
      "desc": "Remote ollama chat/completion",
      "method": "POST",
      "url": "http://jonathan.sh.intel.com:11434/api/chat",
      "api_flavor": "ollama",
      "properties": {
        "supported_response_mode": ["sync", "stream"],
        "models": ["llama3.1"]
      }
    },
    "local_ollama_chat": {
      "desc": "Local ollamma chat/completion",
      "method": "POST",
      "url": "http://jonathan.sh.intel.com:11434/api/chat",
      "api_flavor": "ollama",
      "properties": {
        "supported_response_mode": ["sync", "stream"],
        "models": ["llama3.1"]
      }
    },
    "local_openai_chat": {
      "desc": "Local openai chat/completion",
      "method": "POST",
      "url": "http://10.239.44.34:1234/v1/chat/completions",
      "api_flavor": "openai",
      "properties": {
        "supported_response_mode": ["sync", "stream"],
        "models": ["lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF"]
      }
    },
    "remote_openai_chat": {
      "desc": "Remote openai chat/completion",
      "method": "POST",
      "url": "http://10.239.44.34:1234/v1/chat/completions",
      "api_flavor": "openai",
      "properties": {
        "supported_response_mode": ["sync", "stream"],
        "models": ["lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF"]
      }
    },

    "local_ollama_models": {
      "desc": "List local ollama models",
      "method": "GET",
      "url": "http://jonathan.sh.intel.com:11434/api/tags",
      "api_flavor": "ollama",
      "properties": {}
    },
    "remote_openai_models": {
      "desc": "Remote openai models",
      "method": "GET",
      "url": "http://10.239.44.34:1234/v1/models",
      "api_flavor": "openai",
      "properties": {}
    },

    "local_ollama_generate": {
      "desc": "Local ollamma generate",
      "method": "POST",
      "url": "http://jonathan.sh.intel.com:11434/api/generate",
      "api_flavor": "ollama",
      "properties": {
        "xpu": ["cpu"],
        "supported_response_mode": ["sync", "stream"],
        "models": ["llama3"]
      }
    },
    "local_ollama_embed": {
      "desc": "Local ollamma embed",
      "method": "POST",
      "url": "http://jonathan.sh.intel.com:11434/api/embed",
      "api_flavor": "ollama",
      "properties": {
        "supported_response_mode": ["sync", "stream"],
        "models": ["all-minilm"]
      }
    },

    "openai_chat_and_function_call": {
      "desc": "OpenAI chat and function call",
      "method": "POST",
      "url": "http://test.com",
      "api_flavor": "openai"
    },
    "remote_uvicorn_tts": {
      "desc": "Remote audio/speech",
      "method": "POST",
      "url": "http://shliclew601.ccr.corp.intel.com:9880/tts",
      "api_flavor": "opac",
      "properties": {}
    }
  },
  "services": {
    "models": {
      "service_providers": {
        "local": "local_ollama_models",
        "remote": "remote_openai_models"
      },
      "hybrid_policy": "default"
    },
    "chat": {
      "service_providers": {
        "local": "local_ollama_chat",
        "remote": "remote_openai_chat"
      },
      "hybrid_policy": "default"
    },
    "generate": {
      "service_providers": {
        "local": "local_ollama_generate"
      },
      "hybrid_policy": "default"
    },
    "embed": {
      "service_providers": {
        "local": "local_ollama_embed"
      },
      "hybrid_policy": "default"
    },
    "function_call": {
      "service_providers": {
        "remote": "openai_chat_and_function_call"
      },
      "hybrid_policy": "always_remote"
    },
    "text_to_speech": {
      "service_providers": {
        "local": "remote_uvicorn_tts",
        "remote": "remote_uvicorn_tts"
      }
    }
  }
}
