[
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-r1-1.5B is a language model developed by the Deepseek team, with approximately 1.5 billion parameters. It is a lightweight version in the Deepseek-R1 model series, suitable for basic tasks and low-resource environments.",
    "flavor": "deepseek",
    "id": "8370398b-5407-402f-a325-336631643637356231393937",
    "name": "deepseek-r1:1.5b",
    "ollama_id": "a42b25d8c10a",
    "params_size": 1.5,
    "service_name": "chat",
    "service_source": "local",
    "size": "1.1GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-r1-7B is a model developed by the Deepseek team, primarily used for large model inference scenarios. It has 7 billion parameters and is suitable for various application scenarios.",
    "flavor": "deepseek",
    "id": "e11bc188-2882-4069-a7ce-316664653130336435353138",
    "name": "deepseek-r1:7b",
    "ollama_id": "0a8c26691023",
    "params_size": 7,
    "service_name": "chat",
    "service_source": "local",
    "size": "4.7GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-r1-8B is a language model based on the Llama architecture, with 8 billion parameters. It has undergone deep distillation processing, enabling the model to perform excellently in complex natural language processing tasks while saving computational resources.",
    "flavor": "deepseek",
    "id": "cce2636f-f7ed-429e-9002-613165393436386336656136",
    "name": "deepseek-r1:8b",
    "ollama_id": "28f8fd6cdc67",
    "params_size": 8,
    "service_name": "chat",
    "service_source": "local",
    "size": "4.9GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-r1-14B is a large-scale language model developed by the Deepseek team, with 14 billion parameters. This model performs excellently in natural language processing tasks and can provide high-quality language understanding and generation capabilities.",
    "flavor": "deepseek",
    "id": "81d25018-1657-46f4-8ceb-373164326466363934393536",
    "name": "deepseek-r1:14b",
    "ollama_id": "ea35dfe18182",
    "params_size": 14,
    "service_name": "chat",
    "service_source": "local",
    "size": "9.0GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-0.5B is the third-generation small parameter model launched by the Aliyun Tongyi Qianwen team, with approximately 500 million parameters. It is a lightweight model that provides core capabilities such as code generation and text understanding, suitable for lightweight natural language tasks.",
    "flavor": "aliyun",
    "id": "413583ae-d856-417d-9c8a-636665303365613262383430",
    "name": "qwen2.5:0.5b",
    "ollama_id": "a8b0c5157701",
    "params_size": 0.5,
    "service_name": "chat",
    "service_source": "local",
    "size": "398MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-1.5B is the third-generation lightweight model launched by the Aliyun Tongyi Qianwen team, with approximately 1.5 billion parameters. While maintaining its lightweight nature, it achieves similar inference capabilities to larger models through architectural optimization and data expansion.",
    "flavor": "aliyun",
    "id": "8fe5daf1-ba66-45de-a431-396463333637613730383364",
    "name": "qwen2.5:1.5b",
    "ollama_id": "65ec06548149",
    "params_size": 1.5,
    "service_name": "chat",
    "service_source": "local",
    "size": "986MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-3B is the third-generation model launched by the Aliyun Tongyi Qianwen team, with approximately 3 billion parameters. It covers 29 languages including Chinese, English, and Japanese, and achieves task processing capabilities similar to 7B parameter models through architectural optimization while maintaining its edge-side deployment advantages.",
    "flavor": "aliyun",
    "id": "f43f36c1-479a-4af7-89d6-363663353031373238306138",
    "name": "qwen2.5:3b",
    "ollama_id": "357c53fb659c",
    "params_size": 3,
    "service_name": "chat",
    "service_source": "local",
    "size": "1.9GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-7B is the third-generation model launched by the Aliyun Tongyi Qianwen team, with approximately 7 billion parameters. It demonstrates performance similar to larger models in long text processing, multilingual support, and professional domain tasks, making it an excellent choice for balancing computing costs and task accuracy.",
    "flavor": "aliyun",
    "id": "76376bdc-004c-47d2-8d73-353934396164333833636331",
    "name": "qwen2.5:7b",
    "ollama_id": "845dbda0ea48",
    "params_size": 7,
    "service_name": "chat",
    "service_source": "local",
    "size": "4.7GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-14B is the third-generation large model launched by the Aliyun Tongyi Qianwen team, with approximately 14.7 billion parameters. It supports multiple languages and excels in mathematical reasoning, code generation, and multilingual tasks.",
    "flavor": "aliyun",
    "id": "8a5da271-8b27-4919-bb76-613938383630333061373964",
    "name": "qwen2.5:14b",
    "ollama_id": "7cdf5a0187d5",
    "params_size": 14,
    "service_name": "chat",
    "service_source": "local",
    "size": "9.0GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "deepscaler-1.5B is a language model optimized through reinforcement learning fine-tuning based on Deepseek-R1-Distilled-Qwen-1.5B, with approximately 1.5 billion parameters, suitable for lightweight device deployment and real-time interactive scenarios.",
    "flavor": "deepseek",
    "id": "df7ac73f-b4b3-4a79-b27e-626235656530613563636263",
    "name": "deepscaler:1.5b",
    "ollama_id": "0031bcf7459f",
    "params_size": 1.5,
    "service_name": "chat",
    "service_source": "local",
    "size": "3.6GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-coder-0.5B is the programming-oriented third-generation model launched by the Aliyun Tongyi Qianwen team, with approximately 500 million parameters. It is designed based on the Qwen2.5 architecture and Transformer decoder, supporting 92 programming languages including Python.",
    "flavor": "aliyun",
    "id": "c00cf249-3991-4cab-aa4f-623661656531643236373630",
    "name": "qwen2.5-coder:0.5b",
    "ollama_id": "d392ed348d5b",
    "params_size": 0.5,
    "service_name": "chat",
    "service_source": "local",
    "size": "531MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-coder-1.5B is the programming-oriented third-generation model launched by the Aliyun Tongyi Qianwen team, with approximately 1.5 billion parameters. It supports 92 programming languages and provides efficient code generation, completion, and repair capabilities for lightweight devices.",
    "flavor": "aliyun",
    "id": "0cfb19fa-2d26-4482-a2e6-306238393134366532333036",
    "name": "qwen2.5-coder:1.5b",
    "ollama_id": "6d3abb8d2d53",
    "params_size": 1.5,
    "service_name": "chat",
    "service_source": "local",
    "size": "986MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-coder-3B is the programming-oriented third-generation model launched by the Aliyun Tongyi Qianwen team, with approximately 3 billion parameters. It is designed based on the Qwen2.5 architecture and Transformer decoder, focusing on enhancing multilingual code generation and optimization capabilities, suitable for medium-complexity programming tasks.",
    "flavor": "aliyun",
    "id": "0819f663-b588-47bc-bf1a-656266393731633932316266",
    "name": "qwen2.5-coder:3b",
    "ollama_id": "e7149271c296",
    "params_size": 3,
    "service_name": "chat",
    "service_source": "local",
    "size": "1.9GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-coder-7B is the programming-oriented third-generation model launched by the Aliyun Tongyi Qianwen team, with approximately 7 billion parameters. It supports 92 programming languages and focuses on improving code reasoning and repair capabilities, suitable for complex programming tasks.",
    "flavor": "aliyun",
    "id": "54904615-fb6f-404e-8446-313064663266663633373663",
    "name": "qwen2.5-coder:7b",
    "ollama_id": "2b0496514337",
    "params_size": 7,
    "service_name": "chat",
    "service_source": "local",
    "size": "4.7GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2.5-coder-14B is the programming-oriented third-generation large model launched by the Aliyun Tongyi Qianwen team, with approximately 14 billion parameters. It supports 92 programming languages and focuses on optimizing collaborative development of large codebases and complex logic reasoning capabilities.",
    "flavor": "aliyun",
    "id": "187c6954-a781-4f8f-a4a2-383531646433623239343837",
    "name": "qwen2.5-coder:14b",
    "ollama_id": "3028237cc8c5",
    "params_size": 14,
    "service_name": "chat",
    "service_source": "local",
    "size": "9.0GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/yi.png",
    "class": [
      "文本生成"
    ],
    "description": "yi-coder-1.5B is an open-source programming assistant model with 150 million parameters from 01.AI, supporting 52 programming languages and excelling in code generation, code completion, and debugging tasks.",
    "flavor": "Yi",
    "id": "f34e6517-8213-4be2-871e-386535343432393331383939",
    "name": "yi-coder:1.5b",
    "ollama_id": "186c460ee707",
    "params_size": 1.5,
    "service_name": "chat",
    "service_source": "local",
    "size": "866MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/yi.png",
    "class": [
      "文本生成"
    ],
    "description": "yi-coder-9B is an open-source code model with 9 billion parameters from 01.AI, supporting 52 programming languages. Its performance in code generation, debugging, and completion tasks surpasses models of similar scale, making it suitable for complex project-level development.",
    "flavor": "Yi",
    "id": "d25e82de-95bc-4c0b-a507-6265376261336334623934",
    "name": "yi-coder:9b",
    "ollama_id": "39c63e7675d7",
    "params_size": 9,
    "service_name": "chat",
    "service_source": "local",
    "size": "5.0GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2-math-1.5B is the second-generation mathematical and reasoning model launched by the Aliyun Tongyi Qianwen team, with approximately 1.5 billion parameters, suitable for multi-step logical reasoning and competitive math problem solving.",
    "flavor": "aliyun",
    "id": "31ee3e7e-51a8-4a60-a20a-383131623536363061383533",
    "name": "qwen2-math:1.5b",
    "ollama_id": "a4fdda0c6cc5",
    "params_size": 1.5,
    "think": true,
    "service_name": "chat",
    "service_source": "local",
    "size": "935MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2-math-7B is the second-generation mathematical and reasoning model launched by the Aliyun Tongyi Qianwen team, with approximately 7 billion parameters. It excels in multi-step logical reasoning and competitive math problem solving, and supports bilingual mathematical problem analysis in Chinese and English.",
    "flavor": "aliyun",
    "id": "3421af88-f447-43f8-a7d3-356539626463303364616134",
    "name": "qwen2-math:7b",
    "ollama_id": "28cc3a337734",
    "params_size": 7,
    "think": true,
    "service_name": "chat",
    "service_source": "local",
    "size": "4.4GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/glm.png",
    "class": [
      "文本生成"
    ],
    "description": "glm4:9B is a 9-billion parameter multimodal conversational model open-sourced by Tsinghua ZhipuAI, supporting 26 languages and possessing code execution, web Browse, and multimodal interaction capabilities.",
    "flavor": "zhipuAi",
    "id": "0ce77296-e636-4794-af32-613663656161343664383131",
    "name": "glm4:9b",
    "ollama_id": "5b699761eca5",
    "think": true,
    "params_size": 9,
    "service_name": "chat",
    "service_source": "local",
    "size": "5.5GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-coder-v2:16B is a large code model with 16 billion parameters launched by Deepseek, supporting code generation and understanding tasks for 338 programming languages.",
    "flavor": "deepseek",
    "id": "b27b54f2-914b-4357-9149-303033663639616266363837",
    "name": "deepseek-coder-v2:16b",
    "ollama_id": "63fb193b3a9b",
    "params_size": 14,
    "service_name": "chat",
    "service_source": "local",
    "size": "8.9GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2-0.5B is the second-generation model launched by the Aliyun Tongyi Qianwen team, with approximately 500 million parameters, developed for entry-level applications and small tasks.",
    "flavor": "aliyun",
    "id": "95deb322-1756-453a-8d94-303161663535646363623732",
    "name": "qwen2:0.5b",
    "ollama_id": "6f48b936a09f",
    "params_size": 0.5,
    "service_name": "chat",
    "service_source": "local",
    "size": "352MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2-1.5B is the second-generation model launched by the Aliyun Tongyi Qianwen team, with approximately 1.5 billion parameters, excelling in tasks such as text classification and mathematical reasoning.",
    "flavor": "aliyun",
    "id": "155e7f18-81a0-4467-b904-623962333138626537363966",
    "name": "qwen2:1.5b",
    "ollama_id": "f6daf2b25194",
    "params_size": 1.5,
    "service_name": "chat",
    "service_source": "local",
    "size": "935MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen2-7B is the second-generation model launched by the Aliyun Tongyi Qianwen team, with approximately 7 billion parameters, supporting 27 languages.",
    "flavor": "aliyun",
    "id": "f5a3eec7-7cbf-4ee8-965c-626636383239376166306533",
    "name": "qwen2:7b",
    "ollama_id": "dd314f039b9d",
    "params_size": 7,
    "service_name": "chat",
    "service_source": "local",
    "size": "4.4GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-v2:16B is an upgraded large language model developed by the Deepseek team, with approximately 16 billion parameters, excelling in tasks such as code generation and mathematical reasoning.",
    "flavor": "deepseek",
    "id": "584e8ed1-7412-4ff9-86d4-656330303138623739653336",
    "name": "deepseek-v2:16b",
    "ollama_id": "7c8c332f2df7",
    "params_size": 16,
    "service_name": "chat",
    "service_source": "local",
    "size": "8.9GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "codeQwen-7B is a programming model launched by the Aliyun Tongyi Qianwen team, with approximately 7 billion parameters. It supports multilingual programming and serves as the core technical foundation for Tongyi Lingma, providing efficient programming assistance.",
    "flavor": "aliyun",
    "id": "398c9e2c-2049-432e-a4d2-336434323037663434323635",
    "name": "codeqwen:7b",
    "ollama_id": "df352abf55b1",
    "params_size": 7,
    "service_name": "chat",
    "service_source": "local",
    "size": "4.2GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen-0.5B is a lightweight model launched by the Aliyun Tongyi Qianwen team, with approximately 500 million parameters, specially designed for low-cost deployment and suitable for entry-level AI application scenarios.",
    "flavor": "aliyun",
    "id": "f0a80611-1cee-458b-84e4-356132313463393138356638",
    "name": "qwen:0.5b",
    "ollama_id": "b5dc5e784f2a",
    "params_size": 0.5,
    "service_name": "chat",
    "service_source": "local",
    "size": "395MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen-1.8B is a model launched by the Aliyun Tongyi Qianwen team, with approximately 1.8 billion parameters, possessing multilingual processing capabilities and a sparse attention mechanism, suitable for text generation, question answering, and other tasks in lightweight scenarios.",
    "flavor": "aliyun",
    "id": "007205d8-7c85-4a61-ac09-386366653639343665376434",
    "name": "qwen:1.8b",
    "ollama_id": "b6e8ec2e7126",
    "params_size": 1.8,
    "service_name": "chat",
    "service_source": "local",
    "size": "1.1GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen-4B is a model launched by the Aliyun Tongyi Qianwen team, with approximately 4 billion parameters. It supports multiple languages and is suitable for medium-load scenarios such as localized code generation and document analysis.",
    "flavor": "aliyun",
    "id": "12dd9b46-a18b-43ba-a87f-316261316336636466356233",
    "name": "qwen:4b",
    "ollama_id": "d53d04290064",
    "params_size": 4,
    "service_name": "chat",
    "service_source": "local",
    "size": "2.3GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/qwen.png",
    "class": [
      "文本生成"
    ],
    "description": "Qwen-7B is a model launched by the Aliyun Tongyi Qianwen team, with approximately 7 billion parameters. It is suitable for medium-to-high load scenarios such as text generation, intelligent question answering, and localized knowledge base construction.",
    "flavor": "aliyun",
    "id": "150fc9f8-73c0-44f8-a00b-363865643336653338383462",
    "name": "qwen:7b",
    "ollama_id": "2091ee8c8d8f",
    "params_size": 7,
    "service_name": "chat",
    "service_source": "local",
    "size": "4.5GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "Deepseek-llm-7B is a Chinese/multilingual large model developed by the Deepseek team, with approximately 7 billion parameters, excelling in tasks such as mathematical reasoning and code generation.",
    "flavor": "deepseek",
    "id": "49321b3f-fceb-4c90-85fc-643563376131356439626463",
    "name": "deepseek-llm:7b",
    "ollama_id": "9aab369a853b",
    "params_size": 7,
    "service_name": "chat",
    "service_source": "local",
    "size": "4.0GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/Nomic.png",
    "class": [
      "嵌入模型"
    ],
    "description": "nomic-embed-text is a high-performance open embedding model with a large token context window, and a sentence embedding model based on the Sentence Transformers library, specifically for feature extraction and sentence similarity calculation. It performs well on multiple tasks, especially in classification, retrieval, and clustering tasks.",
    "flavor": "Nomic",
    "id": "5106a180-2faa-4700-86d1-613631623633373561616566",
    "name": "nomic-embed-text",
    "ollama_id": "0a109f422b47",
    "service_name": "embed",
    "service_source": "local",
    "size": "274MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/Mixedbread.png",
    "class": [
      "嵌入模型"
    ],
    "description": "mxbai-embed-large is a state-of-the-art large embedding model from mixedbread.ai, which achieves SOTA performance for Bert-large scale models on MTEB. Its performance surpasses commercial models such as OpenAItext-embedding-3-large and is comparable to models 20 times its size, trained without MTEB data overlap, indicating the model's good generalization ability across multiple domains, tasks, and text lengths.",
    "flavor": "Mixedbread",
    "id": "0448c94a-5caa-4583-bef0-633735666539366164393339",
    "name": "mxbai-embed-large",
    "ollama_id": "468836162de7",
    "service_name": "embed",
    "service_source": "local",
    "size": "670MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/BAAI.png",
    "class": [
      "嵌入模型"
    ],
    "description": "BGE-M3 is a new model released by BAAI, known for its versatility, multilingualism, and multi-granularity.",
    "flavor": "BAAI",
    "id": "40b25b4d-0a1e-408a-a066-656562333330323439663535",
    "name": "bge-m3:567m",
    "ollama_id": "790764642607",
    "service_name": "embed",
    "service_source": "local",
    "size": "1.2GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/Snowflake.png",
    "class": [
      "嵌入模型"
    ],
    "description": "snowflake-arctic-embed is a suite of text embedding models focused on creating high-quality retrieval models optimized for performance.\n\nThese models are trained using existing open-source text representation models (e.g., bert-base-uncased) and undergo training in a multi-stage pipeline to optimize their retrieval performance.",
    "flavor": "Snowflake",
    "id": "fb6c6f6d-b707-4012-9f43-353463643533313165616636",
    "name": "snowflake-arctic-embed",
    "ollama_id": "21ab8b9b0545",
    "service_name": "embed",
    "service_source": "local",
    "size": "669MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/BAAI.png",
    "class": [
      "嵌入模型"
    ],
    "description": "bge-large can map any text into low-dimensional dense vectors for tasks such as retrieval, classification, clustering, or semantic search. It can also be used as a vector database for LLMs.",
    "flavor": "BAAI",
    "id": "87c0b009-2d93-4f00-9662-333037666261373163373263",
    "name": "quentinz/bge-large-zh-v1.5:f16",
    "ollama_id": "bc8ca0995fcd651",
    "service_name": "embed",
    "service_source": "local",
    "size": "671MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/BAAI.png",
    "class": [
      "嵌入模型"
    ],
    "description": "bge-large can map any text into low-dimensional dense vectors for tasks such as retrieval, classification, clustering, or semantic search. It can also be used as a vector database for LLMs.",
    "flavor": "BAAI",
    "id": "5d204ef2-fc6a-4545-9c98-306139646136346637613561",
    "name": "quentinz/bge-base-zh-v1.5:f16",
    "ollama_id": "cd232613fa6f",
    "service_name": "embed",
    "service_source": "local",
    "size": "205MB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/Snowflake.png",
    "class": [
      "嵌入模型"
    ],
    "description": "Snowflake's cutting-edge embedding model. Arctic Embed 2.0 adds multilingual support without sacrificing English performance or scalability.",
    "flavor": "Snowflake",
    "id": "fc047dcd-78fd-49c9-b33c-616264326336376333653936",
    "name": "snowflake-arctic-embed2",
    "ollama_id": "5de93a84837d",
    "service_name": "embed",
    "service_source": "local",
    "size": "1.2GB"
  },
  {
    "api_flavor": "ollama",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/IBM.png",
    "class": [
      "嵌入模型"
    ],
    "description": "IBM Granite Embedding 278M model is a plain text dense dual-encoder embedding model, suitable for multilingual use cases. These models are designed to generate fixed-length vector representations for a given text block, which can be used for text similarity, retrieval, and search applications.",
    "flavor": "IBM",
    "id": "d8c109c0-f063-48a5-9b4d-613139303566303732386335",
    "name": "granite-embedding:278m",
    "ollama_id": "1a37926bf842",
    "service_name": "embed",
    "service_source": "local",
    "size": "563MB"
  },
  {
    "api_flavor": "baidu",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/baidu.png",
    "class": [
      "文本生成"
    ],
    "description": "a chat model",
    "flavor": "baidu",
    "id": "8bb09185-1681-4277-8837-353835333363363235313064",
    "input_length": 8000,
    "name": "ernie-3.5-8k",
    "output_length": 5000,
    "service_name": "chat",
    "service_source": "remote"
  },
  {
    "api_flavor": "aliyun",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/aliyun.png",
    "class": [
      "文本生成"
    ],
    "description": "The best-performing model in the Tongyi Qianwen series, suitable for complex, multi-step tasks.",
    "flavor": "aliyun",
    "id": "5a862bce-3679-4c7c-bd14-616233363335323136616633",
    "max_input": 30720,
    "max_output": 8192,
    "name": "qwen-max",
    "service_name": "chat",
    "service_source": "remote"
  },
  {
    "api_flavor": "aliyun",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/aliyun.png",
    "class": [
      "文本生成"
    ],
    "description": "The QwQ inference model trained based on the Qwen2.5 model, which significantly enhances the model's inference capabilities through reinforcement learning. The model's core metrics for mathematics and code (AIME 24/25, LiveCodeBench) and some general metrics (IFEval, LiveBench, etc.) have reached the level of the full-fledged DeepSeek-R1.",
    "flavor": "aliyun",
    "id": "ccd2bca0-547d-4e56-98ac-386131336330303536303435",
    "max_input": 129024,
    "max_output": 8192,
    "name": "qwen-plus",
    "service_name": "chat",
    "service_source": "remote"
  },
  {
    "api_flavor": "aliyun",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/aliyun.png",
    "class": [
      "文本生成"
    ],
    "description": "The fastest and lowest-cost model in the Tongyi Qianwen series, suitable for simple tasks.",
    "flavor": "aliyun",
    "id": "faf74f1d-d94e-4918-b834-336162623739373834656130",
    "max_input": 1000000,
    "max_output": 1000000,
    "name": "qwen-turbo",
    "service_name": "chat",
    "service_source": "remote"
  },
  {
    "api_flavor": "aliyun",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/aliyun.png",
    "class": [
      "文本生成"
    ],
    "description": "The model with the longest context window, balanced capabilities, and lower cost in the Tongyi Qianwen series, suitable for long text analysis, information extraction, summarization, and classification tagging tasks.",
    "flavor": "aliyun",
    "id": "adb25aea-4231-4cf9-8cea-313465653137306235323937",
    "max_input": 10000000,
    "max_output": 10000000,
    "name": "qwen-long",
    "service_name": "chat",
    "service_source": "remote"
  },
  {
    "api_flavor": "tencent",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/tencent.png",
    "class": [
      "文本生成"
    ],
    "description": "The model with the longest context window, balanced capabilities, and lower cost in the Tongyi Qianwen series, suitable for long text analysis, information extraction, summarization, and classification tagging tasks.",
    "flavor": "tencent",
    "id": "c99cb190-6269-4741-91f0-363366313566373363346539",
    "max_input": 28000,
    "max_output": 4000,
    "name": "hunyuan-turbo",
    "service_name": "chat",
    "service_source": "remote"
  },
  {
    "api_flavor": "tencent",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/tencent.png",
    "class": [
      "文本生成"
    ],
    "description": "The industry's first super-large scale Hybrid-Transformer-Mamba inference model, extending inference capabilities, with ultra-fast decoding speed, further aligning with human preferences.",
    "flavor": "tencent",
    "id": "457ff64a-1683-4f38-b15b-333666623366656562326466",
    "max_input": 28000,
    "max_output": 64000,
    "name": "hunyuan-t1-latest",
    "service_name": "chat",
    "service_source": "remote"
  },
  {
    "api_flavor": "tencent",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/tencent.png",
    "class": [
      "文本生成"
    ],
    "description": "The Hunyuan-large model has a total of approximately 389B parameters and approximately 52B active parameters, making it the industry's largest and most effective Transformer-architecture MoE model.",
    "flavor": "tencent",
    "id": "99d2e8fc-4360-4515-a059-356334313837376464653636",
    "max_input": 28000,
    "max_output": 4000,
    "name": "hunyuan-large",
    "service_name": "chat",
    "service_source": "remote"
  },
  {
    "api_flavor": "tencent",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/tencent.png",
    "class": [
      "文本生成"
    ],
    "description": "Adopts a better routing strategy while alleviating issues of load balancing and expert convergence. MOE-32K is more cost-effective and can handle long text inputs while balancing performance and price.",
    "flavor": "tencent",
    "id": "c9eae45e-0a5b-4995-83c0-323935393530373034656662",
    "max_input": 30000,
    "max_output": 2000,
    "name": "hunyuan-standard",
    "service_name": "chat",
    "service_source": "remote"
  },
  {
    "api_flavor": "tencent",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/tencent.png",
    "class": [
      "文本生成"
    ],
    "description": "Unifies the style of mathematical problem-solving steps and strengthens multi-turn mathematical Q&A. Optimizes text creation style, removes AI-like phrasing, and enhances literary flair.",
    "flavor": "tencent",
    "id": "c1c634c8-b7ee-4dd2-93dd-643439666434623534396564",
    "max_input": 24000,
    "max_output": 8000,
    "name": "hunyuan-turbos-latest",
    "service_name": "chat",
    "service_source": "remote"
  },
  {
    "api_flavor": "deepseek",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "deepseek-reasoning is a reasoning model launched by DeepSeek. Before outputting the final answer, the model first outputs a chain of thought to improve the accuracy of the final answer. Our API provides users with access to the deepseek-reasoner's chain of thought for viewing, display, and distillation.",
    "flavor": "deepseek",
    "id": "da96ac96-515b-4706-8c59-663138303364336463333236",
    "max_input": 64000,
    "max_output": 64000,
    "name": "deepseek-resoning",
    "think": true,
    "service_name": "chat",
    "service_source": "remote"
  },
  {
    "api_flavor": "deepseek",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/deepseek.png",
    "class": [
      "文本生成"
    ],
    "description": "deepseek-reasoning is a conversational model (deepseek-v3) launched by DeepSeek.",
    "flavor": "deepseek",
    "id": "88f7a912-6ded-4fc0-89c9-343236623138363739373630",
    "max_input": 0,
    "max_output": 0,
    "think": true,
    "name": "deepseek-chat",
    "service_name": "chat",
    "service_source": "remote"
  },
  {
    "api_flavor": "tencent",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/tencent.png",
    "class": [
      "文本向量化"
    ],
    "description": "an embedding model",
    "flavor": "tencent",
    "id": "4bba3240-63d2-4002-b3a6-636538396336646639653533",
    "max_input": 0,
    "max_output": 0,
    "name": "hunyuan-embedding",
    "service_name": "embed",
    "service_source": "remote"
  },
  {
    "api_flavor": "baidu",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/baidu.png",
    "class": [
      "文本向量化"
    ],
    "description": "an embedding model",
    "flavor": "baidu",
    "id": "dc252a06-ea7d-4bfc-8403-303132323737333832356533",
    "max_input": 384,
    "max_output": 0,
    "name": "embedding-v1",
    "service_name": "embed",
    "service_source": "remote"
  },
  {
    "api_flavor": "aliyun",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/aliyun.png",
    "class": [
      "文本向量化"
    ],
    "description": "an embedding model",
    "flavor": "aliyun",
    "id": "a540bf9e-ca8d-4c36-8927-343466303236633766393239",
    "max_input": 512000,
    "max_output": 0,
    "name": "text-embedding-v1",
    "service_name": "embed",
    "service_source": "remote"
  },
  {
    "api_flavor": "aliyun",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/aliyun.png",
    "class": [
      "文本向量化"
    ],
    "description": "an embedding model",
    "flavor": "aliyun",
    "id": "25c33cd6-280e-4498-a3cf-623535633838383834623432",
    "max_input": 512000,
    "max_output": 0,
    "name": "text-embedding-v2",
    "service_name": "embed",
    "service_source": "remote"
  },
  {
    "api_flavor": "aliyun",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/aliyun.png",
    "class": [
      "文本向量化"
    ],
    "description": "an embedding model",
    "flavor": "aliyun",
    "id": "a970a6df-d623-46b1-b402-376230336162666464346332",
    "max_input": 81920,
    "max_output": 0,
    "name": "text-embedding-v3",
    "service_name": "embed",
    "service_source": "remote"
  },
  {
    "api_flavor": "aliyun",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/aliyun.png",
    "class": [
      "文生图"
    ],
    "description": "Fast generation speed, comprehensive effects, and high cost-effectiveness. Corresponds to the Tongyi Wanxiang official website 2.1 speed model.",
    "flavor": "aliyun",
    "id": "07cd2cf5-30ce-45e8-9c7a-616237666561323539333038",
    "max_input": 0,
    "max_output": 0,
    "name": "wanx2.1-t2i-turbo",
    "service_name": "text-to-image",
    "service_source": "remote"
  },
  {
    "api_flavor": "aliyun",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/aliyun.png",
    "class": [
      "文生图"
    ],
    "description": "Generates richer image details, slower speed. Corresponds to the Tongyi Wanxiang official website 2.1 professional model.",
    "flavor": "aliyun",
    "id": "084e31a8-9e18-4223-8cf0-633031303339363037353365",
    "max_input": 0,
    "max_output": 0,
    "name": "wanx2.1-t2i-plus",
    "service_name": "text-to-image",
    "service_source": "remote"
  },
  {
    "api_flavor": "aliyun",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/aliyun.png",
    "class": [
      "文生图"
    ],
    "description": "Excels in textured portraits, with moderate speed and lower cost. Corresponds to the Tongyi Wanxiang official website 2.0 speed model.",
    "flavor": "aliyun",
    "id": "c4754885-63c6-49b1-ae75-34363461306566637366463",
    "max_input": 0,
    "max_output": 0,
    "name": "wanx2.0-t2i-turbo",
    "service_name": "text-to-image",
    "service_source": "remote"
  },
  {
    "api_flavor": "baidu",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/baidu.png",
    "class": [
      "文生图"
    ],
    "description": "a text-to-image model",
    "flavor": "baidu",
    "id": "f9283701-a775-4b49-b7b1-336133653434363365663635",
    "max_input": 200,
    "max_output": 0,
    "name": "irag-1.0",
    "service_name": "text-to-image",
    "service_source": "remote"
  },
  {
    "api_flavor": "tencent",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/tencent.png",
    "class": [
      "文生图"
    ],
    "description": "a text-to-image model",
    "flavor": "tencent",
    "id": "864704fd-4894-4850-97f9-65353134653666637333963",
    "max_input": 0,
    "max_output": 0,
    "name": "hunyuan-DiT",
    "service_name": "text-to-image",
    "service_source": "remote"
  },
  {
    "api_flavor": "openvino",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/openvino_logo.png",
    "class": [
      "文生图"
    ],
    "description": "a text-to-image model",
    "flavor": "openvino",
    "id": "7d4b6476",
    "max_input": 0,
    "max_output": 0,
    "name": "OpenVINO/stable-diffusion-v1-5-fp16-ov",
    "service_name": "text-to-image",
    "service_source": "local",
    "size": "3.1GB"
  },
  {
    "api_flavor": "openvino",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/openvino_logo.png",
    "class": [
      "文生图"
    ],
    "description": "a text-to-image model",
    "flavor": "openvino",
    "id": "1ef250f0",
    "max_input": 0,
    "max_output": 0,
    "name": "OpenVINO/FLUX.1-schnell-fp16-ov",
    "service_name": "text-to-image",
    "service_source": "local",
    "size": "34GB"
  },
  {
    "api_flavor": "openvino",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/openvino_logo.png",
    "class": [
      "文生图"
    ],
    "description": "a text-to-image model",
    "flavor": "openvino",
    "id": "a781cc51",
    "max_input": 0,
    "max_output": 0,
    "name": "OpenVINO/FLUX.1-schnell-int8-ov",
    "service_name": "text-to-image",
    "service_source": "local",
    "size": "17GB"
  },
  {
    "api_flavor": "openvino",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/openvino_logo.png",
    "class": [
      "文生图"
    ],
    "description": "a text-to-image model",
    "flavor": "openvino",
    "id": "a550a9eb",
    "max_input": 0,
    "max_output": 0,
    "name": "OpenVINO/stable-diffusion-v1-5-int8-ov",
    "service_name": "text-to-image",
    "service_source": "local",
    "size": "2.3GB"
  },
  {
    "api_flavor": "openvino",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/openvino_logo.png",
    "class": [
      "文生图"
    ],
    "description": "a text-to-image model",
    "flavor": "openvino",
    "id": "8e898f06",
    "max_input": 0,
    "max_output": 0,
    "name": "OpenVINO/LCM_Dreamshaper_v7-fp16-ov",
    "service_name": "text-to-image",
    "service_source": "local",
    "size": "1.3GB"
  },
  {
    "api_flavor": "openvino",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/openvino_logo.png",
    "class": [
      "语音识别"
    ],
    "description": "a speech-to-text model",
    "flavor": "openvino",
    "id": "0b39a78b",
    "max_input": 0,
    "max_output": 0,
    "name": "NamoLi/whisper-large-v3-ov",
    "service_name": "speech-to-text",
    "service_source": "local",
    "size": "5.75GB"
  }
,
  {
    "api_flavor": "openvino",
    "avatar": "http://smartvision-aipc-open.oss-cn-hangzhou.aliyuncs.com/aog/icon/openvino_logo.png",
    "class": [
      "语音识别"
    ],
    "description": "a speech-to-text model",
    "flavor": "openvino",
    "id": "0b39a78b",
    "max_input": 0,
    "max_output": 0,
    "name": "NamoLi/whisper-large-v3-ov",
    "service_name": "speech-to-text-ws",
    "service_source": "local",
    "size": "5.75GB"
  }
]